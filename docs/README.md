# æ•°æ®æ¨¡å‹æ–‡æ¡£

## ğŸ“‹ æ¦‚è¿°

æœ¬æ¨¡å—æä¾›äº† RAG ç³»ç»Ÿçš„æ ¸å¿ƒæ•°æ®æ¨¡å‹ï¼ŒåŒ…æ‹¬æ–‡æ¡£ï¼ˆDocumentï¼‰å’Œåˆ†å—ï¼ˆChunkï¼‰çš„æ•°æ®ç»“æ„åŠå…¶å…³è”å…³ç³»ã€‚

## ğŸ—ï¸ æ¨¡å‹æ¶æ„

```
BaseModel (åŸºç¡€æ¨¡å‹)
    â†“
    â”œâ”€â”€ Document (æ–‡æ¡£æ¨¡å‹)
    â””â”€â”€ Chunk (åˆ†å—æ¨¡å‹)

DocumentRepository (æ•°æ®ä»“åº“)
    â”œâ”€â”€ ç®¡ç† Documents
    â”œâ”€â”€ ç®¡ç† Chunks
    â””â”€â”€ ç®¡ç† ChunkRelations
```

## ğŸ“¦ æ ¸å¿ƒæ¨¡å‹

### 1. BaseModel (åŸºç¡€æ¨¡å‹)

æ‰€æœ‰æ•°æ®æ¨¡å‹çš„åŸºç±»ï¼Œæä¾›é€šç”¨åŠŸèƒ½ã€‚

**æ ¸å¿ƒå­—æ®µ**:
- `id`: å”¯ä¸€æ ‡è¯†ç¬¦ (UUID)
- `created_at`: åˆ›å»ºæ—¶é—´
- `updated_at`: æ›´æ–°æ—¶é—´
- `metadata`: å…ƒæ•°æ®å­—å…¸

**æ ¸å¿ƒæ–¹æ³•**:
- `to_dict()`: è½¬æ¢ä¸ºå­—å…¸
- `to_json()`: è½¬æ¢ä¸º JSON
- `from_dict()`: ä»å­—å…¸åˆ›å»º
- `from_json()`: ä» JSON åˆ›å»º

### 2. Document (æ–‡æ¡£æ¨¡å‹)

è¡¨ç¤ºä¸€ä¸ªå®Œæ•´çš„æ–‡æ¡£ã€‚

**æ ¸å¿ƒå­—æ®µ**:
```python
@dataclass
class Document(BaseModel):
    # åŸºæœ¬ä¿¡æ¯
    title: str              # æ ‡é¢˜
    content: str            # å†…å®¹
    source: str             # æ¥æº
    doc_type: DocumentType  # ç±»å‹ (TEXT, PDF, WORD, etc.)
    status: DocumentStatus  # çŠ¶æ€ (PENDING, PROCESSING, COMPLETED, etc.)
    
    # åˆ†ç±»
    category: str           # åˆ†ç±»
    tags: List[str]         # æ ‡ç­¾
    
    # å…³è”
    chunk_ids: List[str]    # å…³è”çš„åˆ†å— ID
    
    # ç»Ÿè®¡
    char_count: int         # å­—ç¬¦æ•°
    word_count: int         # è¯æ•°
    chunk_count: int        # åˆ†å—æ•°
    entity_count: int       # å®ä½“æ•°
    relation_count: int     # å…³ç³»æ•°
```

**çŠ¶æ€æšä¸¾**:
```python
class DocumentStatus(Enum):
    PENDING = "pending"         # å¾…å¤„ç†
    PROCESSING = "processing"   # å¤„ç†ä¸­
    COMPLETED = "completed"     # å·²å®Œæˆ
    FAILED = "failed"          # å¤±è´¥
    ARCHIVED = "archived"      # å·²å½’æ¡£
```

**ç±»å‹æšä¸¾**:
```python
class DocumentType(Enum):
    TEXT = "text"
    PDF = "pdf"
    WORD = "word"
    HTML = "html"
    MARKDOWN = "markdown"
    JSON = "json"
    OTHER = "other"
```

**å¸¸ç”¨æ–¹æ³•**:
- `add_chunk(chunk_id)`: æ·»åŠ åˆ†å—
- `remove_chunk(chunk_id)`: ç§»é™¤åˆ†å—
- `set_status(status)`: è®¾ç½®çŠ¶æ€
- `add_tag(tag)`: æ·»åŠ æ ‡ç­¾
- `get_summary()`: è·å–æ‘˜è¦
- `is_processed()`: æ˜¯å¦å·²å¤„ç†
- `has_chunks()`: æ˜¯å¦æœ‰åˆ†å—

### 3. Chunk (åˆ†å—æ¨¡å‹)

è¡¨ç¤ºæ–‡æ¡£çš„ä¸€ä¸ªåˆ†å—ã€‚

**æ ¸å¿ƒå­—æ®µ**:
```python
@dataclass
class Chunk(BaseModel):
    # åŸºæœ¬ä¿¡æ¯
    content: str            # å†…å®¹
    chunk_type: ChunkType   # ç±»å‹ (SEMANTIC, FIXED, etc.)
    
    # å…³è”
    document_id: str        # æ‰€å±æ–‡æ¡£ ID
    parent_chunk_id: str    # çˆ¶åˆ†å— ID
    child_chunk_ids: List[str]  # å­åˆ†å— ID
    
    # ä½ç½®
    chunk_index: int        # åœ¨æ–‡æ¡£ä¸­çš„åºå·
    start_pos: int          # èµ·å§‹ä½ç½®
    end_pos: int            # ç»“æŸä½ç½®
    
    # å‘é‡
    embedding: np.ndarray   # åµŒå…¥å‘é‡
    embedding_model: str    # æ¨¡å‹åç§°
    vector_id: str          # å‘é‡åº“ ID
    
    # çŸ¥è¯†å›¾è°±
    entities: List[str]     # å®ä½“åˆ—è¡¨
    relations: List[Dict]   # å…³ç³»åˆ—è¡¨
    
    # è¯­ä¹‰
    keywords: List[str]     # å…³é”®è¯
    summary: str            # æ‘˜è¦
```

**åˆ†å—ç±»å‹æšä¸¾**:
```python
class ChunkType(Enum):
    FIXED = "fixed"
    SEMANTIC = "semantic"
    RECURSIVE = "recursive"
    PARAGRAPH = "paragraph"
    SENTENCE = "sentence"
    CUSTOM = "custom"
```

**å¸¸ç”¨æ–¹æ³•**:
- `set_embedding(embedding, model)`: è®¾ç½®åµŒå…¥å‘é‡
- `add_entity(entity)`: æ·»åŠ å®ä½“
- `add_relation(subject, predicate, object)`: æ·»åŠ å…³ç³»
- `add_keyword(keyword)`: æ·»åŠ å…³é”®è¯
- `has_embedding()`: æ˜¯å¦æœ‰åµŒå…¥
- `has_entities()`: æ˜¯å¦æœ‰å®ä½“
- `get_text_preview(length)`: è·å–æ–‡æœ¬é¢„è§ˆ

### 4. DocumentRepository (æ•°æ®ä»“åº“)

ç®¡ç†æ–‡æ¡£å’Œåˆ†å—çš„å­˜å‚¨ã€æŸ¥è¯¢ã€‚

**æ ¸å¿ƒåŠŸèƒ½**:

#### æ–‡æ¡£æ“ä½œ
```python
# æ·»åŠ æ–‡æ¡£
doc_id = repo.add_document(document)

# è·å–æ–‡æ¡£
doc = repo.get_document(doc_id)

# æ›´æ–°æ–‡æ¡£
repo.update_document(document)

# åˆ é™¤æ–‡æ¡£
repo.delete_document(doc_id, delete_chunks=True)

# æŸ¥æ‰¾æ–‡æ¡£
docs = repo.find_documents(
    status=DocumentStatus.COMPLETED,
    category="AI",
    tags=["æœºå™¨å­¦ä¹ "]
)
```

#### åˆ†å—æ“ä½œ
```python
# æ·»åŠ åˆ†å—
chunk_id = repo.add_chunk(chunk)

# è·å–åˆ†å—
chunk = repo.get_chunk(chunk_id)

# è·å–æ–‡æ¡£çš„æ‰€æœ‰åˆ†å—
chunks = repo.get_document_chunks(doc_id)

# æŸ¥æ‰¾åˆ†å—
chunks = repo.find_chunks(
    document_id=doc_id,
    has_embedding=True,
    has_entities=True
)
```

#### å…³ç³»æ“ä½œ
```python
# æ·»åŠ åˆ†å—å…³ç³»
relation = ChunkRelation(
    source_chunk_id=chunk1.id,
    target_chunk_id=chunk2.id,
    relation_type="next"
)
repo.add_chunk_relation(relation)

# è·å–å…³ç³»
relations = repo.get_chunk_relations(
    source_chunk_id=chunk1.id,
    relation_type="next"
)
```

#### æŒä¹…åŒ–
```python
# ä¿å­˜åˆ°æ–‡ä»¶
repo.save_to_file("./data/repository.json")

# ä»æ–‡ä»¶åŠ è½½
repo = DocumentRepository.load_from_file("./data/repository.json")
```

#### ç»Ÿè®¡åˆ†æ
```python
stats = repo.get_statistics()
# {
#     'total_documents': 10,
#     'total_chunks': 50,
#     'documents_by_status': {...},
#     'documents_by_category': {...},
#     'avg_chunks_per_doc': 5.0,
#     ...
# }
```

## ğŸ’¡ ä½¿ç”¨ç¤ºä¾‹

### ç¤ºä¾‹ 1: åˆ›å»ºæ–‡æ¡£å’Œåˆ†å—

```python
from models import Document, Chunk, DocumentType, ChunkType

# åˆ›å»ºæ–‡æ¡£
doc = Document(
    title="äººå·¥æ™ºèƒ½ç®€ä»‹",
    content="AI æ˜¯è®¡ç®—æœºç§‘å­¦çš„ä¸€ä¸ªåˆ†æ”¯...",
    source="æ•™ç¨‹",
    doc_type=DocumentType.TEXT,
    category="æŠ€æœ¯"
)

# æ·»åŠ æ ‡ç­¾
doc.add_tag("AI")
doc.add_tag("æœºå™¨å­¦ä¹ ")

# åˆ›å»ºåˆ†å—
chunk = Chunk(
    content="AI æ˜¯è®¡ç®—æœºç§‘å­¦çš„ä¸€ä¸ªåˆ†æ”¯...",
    document_id=doc.id,
    chunk_index=0,
    chunk_type=ChunkType.SEMANTIC
)

# å…³è”åˆ†å—
doc.add_chunk(chunk.id)
```

### ç¤ºä¾‹ 2: ä½¿ç”¨ä»“åº“ç®¡ç†

```python
from models import DocumentRepository

# åˆ›å»ºä»“åº“
repo = DocumentRepository()

# æ·»åŠ æ–‡æ¡£å’Œåˆ†å—
repo.add_document(doc)
repo.add_chunk(chunk)

# æŸ¥æ‰¾æ–‡æ¡£
ai_docs = repo.find_documents(category="æŠ€æœ¯")

# è·å–æ–‡æ¡£çš„åˆ†å—
chunks = repo.get_document_chunks(doc.id)

# ç»Ÿè®¡ä¿¡æ¯
stats = repo.get_statistics()
print(f"æ€»æ–‡æ¡£æ•°: {stats['total_documents']}")
```

### ç¤ºä¾‹ 3: å®Œæ•´å·¥ä½œæµ

```python
from models import Document, Chunk, DocumentStatus, DocumentRepository
import numpy as np

# åˆå§‹åŒ–
repo = DocumentRepository()

# 1. åˆ›å»ºå¹¶æ·»åŠ æ–‡æ¡£
doc = Document(
    title="æ·±åº¦å­¦ä¹ æ•™ç¨‹",
    content="æ·±åº¦å­¦ä¹ æ˜¯æœºå™¨å­¦ä¹ çš„åˆ†æ”¯...",
    source="åœ¨çº¿è¯¾ç¨‹",
    category="AI"
)
doc.set_status(DocumentStatus.PROCESSING)
repo.add_document(doc)

# 2. åˆ†å—å¹¶æ·»åŠ 
chunk = Chunk(
    content="æ·±åº¦å­¦ä¹ æ˜¯æœºå™¨å­¦ä¹ çš„åˆ†æ”¯...",
    document_id=doc.id,
    chunk_type=ChunkType.SEMANTIC
)

# 3. è®¾ç½®åµŒå…¥å‘é‡
embedding = np.random.rand(768).astype(np.float32)
chunk.set_embedding(embedding, "nomic-embed-text")

# 4. æ·»åŠ çŸ¥è¯†
chunk.add_entity("æ·±åº¦å­¦ä¹ ")
chunk.add_entity("æœºå™¨å­¦ä¹ ")
chunk.add_relation("æ·±åº¦å­¦ä¹ ", "IS_PART_OF", "æœºå™¨å­¦ä¹ ")

repo.add_chunk(chunk)

# 5. å®Œæˆå¤„ç†
doc.set_status(DocumentStatus.COMPLETED)
doc.vector_stored = True
doc.entity_count = chunk.entity_count
repo.update_document(doc)

# 6. ä¿å­˜
repo.save_to_file("./data/my_repo.json")
```

## ğŸ”— æ¨¡å‹å…³è”å…³ç³»

### Document â†” Chunk (ä¸€å¯¹å¤š)

```python
# æ–‡æ¡£å…³è”åˆ†å—
doc.add_chunk(chunk.id)
doc.chunk_ids  # ['chunk_1', 'chunk_2', ...]

# åˆ†å—å…³è”æ–‡æ¡£
chunk.document_id = doc.id

# é€šè¿‡ä»“åº“è·å–
chunks = repo.get_document_chunks(doc.id)
```

### Chunk â†” Chunk (å¤šå¯¹å¤šå…³ç³»)

```python
from models.repository import ChunkRelation

# åˆ›å»ºå…³ç³»
relation = ChunkRelation(
    source_chunk_id=chunk1.id,
    target_chunk_id=chunk2.id,
    relation_type="next",  # æˆ– "similar", "reference" ç­‰
    weight=1.0
)

repo.add_chunk_relation(relation)
```

### çˆ¶å­åˆ†å—å…³ç³»

```python
# è®¾ç½®çˆ¶å­å…³ç³»
child_chunk.parent_chunk_id = parent_chunk.id
parent_chunk.child_chunk_ids.append(child_chunk.id)
```

### å‰ååˆ†å—å…³ç³»

```python
# è®¾ç½®é¡ºåºå…³ç³»
chunk2.prev_chunk_id = chunk1.id
chunk1.next_chunk_id = chunk2.id
```

## ğŸ“Š æ•°æ®æ¨¡å‹ UML

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          BaseModel                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ + id: str                           â”‚
â”‚ + created_at: datetime              â”‚
â”‚ + updated_at: datetime              â”‚
â”‚ + metadata: Dict                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ + to_dict()                         â”‚
â”‚ + to_json()                         â”‚
â”‚ + from_dict()                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                   â”‚
    â–¼                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Document   â”‚    â”‚    Chunk    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ title       â”‚â—„â”€â”€â”€â”¤ document_id â”‚
â”‚ content     â”‚ 1 *â”‚ content     â”‚
â”‚ chunk_ids[] â”‚â”€â”€â”€â”€â”¤ chunk_index â”‚
â”‚ status      â”‚    â”‚ embedding   â”‚
â”‚ category    â”‚    â”‚ entities[]  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚                  â”‚
       â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
              â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ DocumentRepositoryâ”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚ documents: Dict  â”‚
    â”‚ chunks: Dict     â”‚
    â”‚ relations: List  â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚ add_document()   â”‚
    â”‚ add_chunk()      â”‚
    â”‚ find_documents() â”‚
    â”‚ get_statistics() â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ¯ æœ€ä½³å®è·µ

### 1. æ–‡æ¡£çŠ¶æ€ç®¡ç†

```python
# åˆ›å»ºæ—¶è®¾ç½®ä¸º PENDING
doc = Document(title="...", status=DocumentStatus.PENDING)

# å¼€å§‹å¤„ç†æ—¶æ›´æ–°ä¸º PROCESSING
doc.set_status(DocumentStatus.PROCESSING)

# å¤„ç†å®Œæˆ
doc.set_status(DocumentStatus.COMPLETED)

# å¤„ç†å¤±è´¥
doc.set_status(DocumentStatus.FAILED, error_message="...")
```

### 2. åˆ†å—ç´¢å¼•ç»´æŠ¤

```python
# åˆ›å»ºåˆ†å—æ—¶è®¾ç½®ç´¢å¼•
for i, text in enumerate(chunk_texts):
    chunk = Chunk(
        content=text,
        document_id=doc.id,
        chunk_index=i  # é‡è¦ï¼ç»´æŠ¤é¡ºåº
    )
```

### 3. å…ƒæ•°æ®ä½¿ç”¨

```python
# æ·»åŠ è‡ªå®šä¹‰å…ƒæ•°æ®
doc.update_metadata("processing_version", "v1.2")
doc.update_metadata("processor", "worker-01")

# è·å–å…ƒæ•°æ®
version = doc.get_metadata("processing_version")
```

### 4. æŸ¥è¯¢ä¼˜åŒ–

```python
# åˆ©ç”¨ç´¢å¼•å¿«é€ŸæŸ¥æ‰¾
docs = repo.find_documents(category="AI")  # ä½¿ç”¨ç´¢å¼•

# è‡ªå®šä¹‰è¿‡æ»¤
docs = repo.find_documents(
    filter_func=lambda doc: doc.char_count > 1000
)
```

## ğŸ“ æ³¨æ„äº‹é¡¹

1. **ID ç®¡ç†**: æ‰€æœ‰æ¨¡å‹çš„ ID éƒ½æ˜¯è‡ªåŠ¨ç”Ÿæˆçš„ UUIDï¼Œä¸è¦æ‰‹åŠ¨è®¾ç½®
2. **æ—¶é—´æˆ³**: `created_at` å’Œ `updated_at` ä¼šè‡ªåŠ¨ç»´æŠ¤
3. **å…³è”å…³ç³»**: æ·»åŠ /åˆ é™¤åˆ†å—æ—¶ï¼Œæ–‡æ¡£çš„ `chunk_ids` ä¼šè‡ªåŠ¨æ›´æ–°
4. **æŒä¹…åŒ–**: ä»“åº“æ”¯æŒ JSON åºåˆ—åŒ–ï¼Œä½† numpy æ•°ç»„ä¼šè½¬æ¢ä¸ºåˆ—è¡¨
5. **çº¿ç¨‹å®‰å…¨**: å½“å‰å®ç°ä¸æ˜¯çº¿ç¨‹å®‰å…¨çš„ï¼Œå¤šçº¿ç¨‹ç¯å¢ƒéœ€è¦åŠ é”

## ğŸ”§ æ‰©å±•å»ºè®®

### æ·»åŠ æ–°å­—æ®µ

```python
from models import Document
from dataclasses import dataclass, field

@dataclass
class ExtendedDocument(Document):
    custom_field: str = ""
    custom_list: List[str] = field(default_factory=list)
```

### è‡ªå®šä¹‰æŸ¥è¯¢

```python
# å®ç°å¤æ‚æŸ¥è¯¢é€»è¾‘
def find_large_documents(repo: DocumentRepository, min_size: int):
    return repo.find_documents(
        filter_func=lambda doc: doc.char_count >= min_size
    )
```

## ğŸ“š æ›´å¤šç¤ºä¾‹

æŸ¥çœ‹ `example_models_usage.py` è·å–å®Œæ•´çš„ä½¿ç”¨ç¤ºä¾‹ã€‚

## ğŸ¤ è´¡çŒ®

æ¬¢è¿æäº¤ Issue å’Œ Pull Requestï¼

